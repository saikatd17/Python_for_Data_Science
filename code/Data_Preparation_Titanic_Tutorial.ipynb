{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "078f9f34",
   "metadata": {},
   "source": [
    "# Data Pre-processing\n",
    "\n",
    "Using the Titanic dataset from [this](https://www.kaggle.com/c/titanic/overview) Kaggle competition.\n",
    "\n",
    "This dataset contains information about 891 people who were on board the ship when departed on April 15th, 1912. As noted in the description on Kaggle's website, some people aboard the ship were more likely to survive the wreck than others. There were not enough lifeboats for everybody so women, children, and the upper-class were prioritized. Using the information about these 891 passengers, the challenge is to build a model to predict which people would survive based on the following fields:\n",
    "\n",
    "- **Name** (str) - Name of the passenger\n",
    "- **Pclass** (int) - Ticket class\n",
    "- **Sex** (str) - Sex of the passenger\n",
    "- **Age** (float) - Age in years\n",
    "- **SibSp** (int) - Number of siblings and spouses aboard\n",
    "- **Parch** (int) - Number of parents and children aboard\n",
    "- **Ticket** (str) - Ticket number\n",
    "- **Fare** (float) - Passenger fare\n",
    "- **Cabin** (str) - Cabin number\n",
    "- **Embarked** (str) - Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d67d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ? as pd # ? pandas\n",
    "import seaborn as sns #built on top of matplotlib so need to load matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e734aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "\n",
    "titanic = pd.read_csv('titanic.csv')\n",
    "# titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc50833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of rows and columns ? shape\n",
    "\n",
    "titanic.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a78f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking column names\n",
    "\n",
    "titanic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9da9d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking columns with missing values ? sum()\n",
    "\n",
    "titanic.isnull().?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d02c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5dba03",
   "metadata": {},
   "source": [
    "# Handling missing values\n",
    "\n",
    "In real world, the datasets are not clean and may have missing values. We must know how to find and deal with these missing values. \n",
    "\n",
    "One of the strategies to deal with missing values is to remove them from the dataset. \n",
    "\n",
    "However, whenever possible, we would like to impute the data, which is a process of filling the missing values. \n",
    "\n",
    "Let us take a look at the example on how to handle missing values. Only 3 columns out of 12 contain missing data. \n",
    "\n",
    "The Age column contains about 20% missing data, which can be dealt with using a technique called imputation, which means replacing the missing values with a known value, such as the mean, median or mode. Age is quantitative, so either mean or median imputation can be done. Embarked is a categorical variable, so mode imputation can be done.\n",
    "\n",
    "As for the Cabin variable containing 77% missing data, we can simply delete the column. More sophisticated methods would be to see how Cabin numbers relate to the Survived or Pclass column and deal with it accordingly. For example, some of the cabins could be located near where the lifeboats are stored, so passengers residing in those cabins could have a higher chance of survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e903c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is dropping all the rows with missing values a good idea? dropna()\n",
    "new_titanic = titanic.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126e68d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if all the missing values are removed\n",
    "\n",
    "new_titanic.isnull().?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e4b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of the new dataset after dropping\n",
    "\n",
    "print(\"No. of rows and columns:\",new_titanic.?) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa1c8dc",
   "metadata": {},
   "source": [
    "## Mode Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d655c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# titanic.pivot_table('PassengerId', index = 'Survived', columns = 'Embarked', aggfunc='count')\n",
    "mode_embarked = titanic['Embarked'].mode()[0] # Python still thinks the mode-aggregated object is a DataSeries (one column of a DataFrame), so we need to select the string inside the DataSeries, hence the [0].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bedd527",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Embarked'].fillna(mode_embarked,inplace = ?) #to replace the existing dataset in fillna use attribute inplace = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1544f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of the new dataset after replacing missing values\n",
    "\n",
    "print(\"No. of rows and columns:\",titanic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7340990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the missing values are removed from Embarked\n",
    "\n",
    "print(titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffe9000",
   "metadata": {},
   "source": [
    "## Mean Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07becaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the mean age of passengers groupby Survived or not ? mean()\n",
    "\n",
    "titanic.groupby('Survived')['Age'].?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f30118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Age'].mean() # Mean age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdcd1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing missing values in the Age column by mean age of the passengers irrespective of survived or not\n",
    "\n",
    "titanic['Age'].fillna(titanic['Age'].mean(), inplace = ?) # ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d121c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of the new dataset after replacing missing values\n",
    "\n",
    "print(\"No. of rows and columns:\",titanic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb4cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the missing values are removed from Embarked\n",
    "\n",
    "print(titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91896468",
   "metadata": {},
   "source": [
    "## Indicator Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aa0b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if there is a pattern between Cabin missing and Survived\n",
    "\n",
    "titanic.groupby(titanic['Cabin'].isnull())['Survived'].mean() # those who died had most missing value of cabin i.e., only 30% of those with missing Cabin value Survived "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312fc2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Cabin'].isnull() # to see the true/ false value for cabin is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3072d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Cabin'] # to see the actual cabin values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29262789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new indicator variable named 'Cabin_ind'\n",
    "\n",
    "titanic['Cabin_ind'] = np.where(titanic['Cabin'].isnull(),'0','1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448475b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see new column is added\n",
    "\n",
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4a3f3c",
   "metadata": {},
   "source": [
    "## Deletion\n",
    "\n",
    "The remaining column with missing data is Cabin (the cabin number). This column contains 77% missing data, so the easiest method would be to get rid of it entirely. Columns can be deleted using the .drop() method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a329f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop(columns='Cabin', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a48769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column Cabin is removed\n",
    "\n",
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60e3a81",
   "metadata": {},
   "source": [
    "Additionally, the columns PassengerId, Name, Ticket are going to be irrelevant for further analysis, so we can drop those as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd2a100",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop(columns=['PassengerId','Name','Ticket'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a301e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns are removed\n",
    "\n",
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35e4ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c457750",
   "metadata": {},
   "source": [
    "## Creating Dummy Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3063f655",
   "metadata": {},
   "source": [
    "We now have 6 numerical columns and three categorical column (Sex, Embarked, Cabin_ind). \n",
    "Also, we need to realize that Pclass is an ordinal categorical variable, with 1st class having a higher status than 2nd class, and so on. These categorical varibales need to be changed into numerics because the machine learning algorithm can only understand numbers.\n",
    "\n",
    "In the case of Pclass, the classes are already represented as numbers but in the reverse order. 3rd class is represented as 3 even though it signifies a lower status than 1st class, which is represented as 1. We could reverse the order and make 3rd class 1 and 1st class 3 but it would be misleading and confusing to interpret.\n",
    "\n",
    "Representing ordinal categorical variables as integers depending on the order of importance assigned to them is known as label encoding. Label encoding can also be used for nominal variables which has no inherent order, for example, Red, Green, Blue being encoded as 1, 2, 3. The disadvantage is that the machine learning algorithm would misinterpret Blue to have a higher quantitative weight than Red even though they are supposed to be equally important.\n",
    "\n",
    "Therefore, we use one-hot encoding for Pclass, Sex, Embarked and Cabin_ind. One-hot encoding separates categories into binary values of 0 and 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55a2ed1",
   "metadata": {},
   "source": [
    "Consider the Sex column first. Initially, it contains the categories \"Male\" and \"Female\", specifying the sex of the passenger. We would like to encode these categories as numbers instead of letters so we apply the pandas method .get_dummies() onto the Sex column. After applying the .get_dummies() method, we see two new columns Sex_female and Sex_male, and the original Sex column has disappeared.\n",
    "\n",
    "In the Sex_male column, if the passenger is male, then he is encoded as 1 and if not she is encoded as 0. The same thing is repeated for the Sex_female column. However, this repetition is undesirable to have because all the required information is already captured within one column. Either keep the Sex_male column and drop the Sex_female, or keep the Sex_female and drop the Sex_male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6713d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.?(titanic, columns=['Sex']) # ? get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ef2824",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ce9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Sex_female\n",
    "titanic.drop('Sex_female', axis=?, inplace=True) # axis=1 specifies that a column is being dropped. If we want to drop rows, we specify axis=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c2760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4960b76",
   "metadata": {},
   "source": [
    "We perform the dummification process of getting dummy columns (the Sex_male and Sex_female are called dummy variables, which are obtained from the original Sex column) for the Pclass column. This time, we add an additional argument drop_first=True to the get_dummies() method to drop one irrelevant column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f5ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.get_dummies(titanic, columns=['Pclass'], drop_first=?) # ? True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d6c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4d3201",
   "metadata": {},
   "source": [
    "In the Pclass column, we had 3 categories: first, second and third class passengers. One-hot encoding for 3 categories works like this: if the passenger is in 1st class, Pclass_1 = 1 and Pclass_2 = Pclass_3 = 0. If the passenger is in 2nd class, Pclass_2 = 1 and Pclass_1 = Pclass_3 = 0, and similarly for 3rd class passengers.\n",
    "\n",
    "In this case, all the information is captured in two columns (the irrelevant column was already dropped by specifying the drop_first=True argument in the previous line of code). Likewise, if we have 4 categories in a column, we create 3 dummies and drop one, and so on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868228bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummies for the other two qualitative variables\n",
    "titanic = pd.get_dummies(titanic, columns = ['Embarked','Cabin_ind'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c8fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b42f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589c4830",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fd89bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Family_Cnt'] = titanic['SibSp'] + titanic['Parch'] # already discussed in previous tutorial on exploratory data analysis\n",
    "sns.catplot(data = titanic,\n",
    "            x = 'Family_Cnt',\n",
    "            y= 'Survived',\n",
    "            kind = 'point',\n",
    "            aspect = 2,\n",
    "            ci = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7dc4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can drop SibSp and Parch from dataset since we wont use them for further analysis\n",
    "\n",
    "titanic.drop(columns=['SibSp','Parch'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffed623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dbdc4e",
   "metadata": {},
   "source": [
    "## Handling Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d201e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = titanic,\n",
    "            x = 'Fare',\n",
    "            kind = 'box',\n",
    "           whis = [5,95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ae2930",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sns.catplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1597221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Winsorise\n",
    "from scipy.stats.mstats import winsorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d8e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trimming from top and bottom\n",
    "\n",
    "titanic['New_fare'] = winsorize(titanic['Fare'], limits=[0.05, 0.05]) # how much to winsorize from top and bottom 5-95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f0dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = titanic,\n",
    "            y = 'New_fare',\n",
    "            kind = 'box',\n",
    "           whis = [5,95]) # Brought the data in normal range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1896bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the pre-processed dataset in local drive\n",
    "\n",
    "titanic.to_csv('titanic_cleaned_1807.csv', encoding = 'utf-8-sig') \n",
    "# files.download('titanic_cleaned_1807.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
