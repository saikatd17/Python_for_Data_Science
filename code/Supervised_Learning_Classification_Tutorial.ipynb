{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28a87a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the standard libraries used for data science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e10601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned Titanic dataset\n",
    "\n",
    "fname = ? # ? \"titanic_cleaned_1807.csv\"\n",
    "# To remove the index column saved as the first column in the dataset while saving dataframe using to_csv()\n",
    "df = pd.read_csv(fname,usecols=range(1,12)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602bb491",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.? # ? shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4b393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371b146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.? # ? info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc3b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only required columns and separate dependent & independent variables\n",
    "\n",
    "cols_needed = ['Age','Family_Cnt','New_fare','Sex_male','Pclass_2','Pclass_3','Embarked_Q','Embarked_S','Cabin_ind_1']\n",
    "\n",
    "X = df[?] # independent variables i.e. ? cols_needed\n",
    "\n",
    "Y = df['Survived'] # dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3bd17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02d0726",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0e0499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for multi-collinearity among independent variables\n",
    "cormat = X.corr()\n",
    "round(cormat,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc3a6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'import' - imports an entire code library, 'from import' - imports a specific member or members of the library.\n",
    "\n",
    "# Split the dataset into training and testing set\n",
    "from ?.model_selection import train_test_split # ? sklearn\n",
    "\n",
    "X_train_data, X_test_data, Y_train_data, Y_test_data = train_test_split(X, Y, test_size=?, random_state=420) # ? test_size= 0.2 for 80-20 split of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a5c6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the shape of train and test data\n",
    "\n",
    "print(X_train_data.shape)\n",
    "print(X_test_data.shape)\n",
    "print(Y_train_data.shape)\n",
    "print(Y_test_data.shape)\n",
    "\n",
    "# To check if there exists a class imbalance\n",
    "#Y_train_data.value_counts()\n",
    "#Y_test_data.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae1493c",
   "metadata": {},
   "source": [
    "# Steps while using sklearn for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edbd587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Logistic Regression model from the sklearn (also known as Scikit-learn) library  \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75f3646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "\n",
    "lr_model = LogisticRegression() # by default max_iter=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30ec9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit logistic regression\n",
    "\n",
    "lr_model.fit(X_train_data,Y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34a3cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the model for test data\n",
    "\n",
    "predictions = lr_model.predict(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec7f998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how the predictions look (the output of lr is a probability that is converted to binary classification using a cutoff)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7430efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of logistic regression - predicted probability between 0 and 1\n",
    "\n",
    "lr_model.predict_proba(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751c4f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model - check the accuracy of the model\n",
    "\n",
    "print('training accuracy:', round(lr_model.score(X_train_data, Y_train_data),2))\n",
    "print('test accuracy:',round(lr_model.score(X_test_data, Y_test_data),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6af126e",
   "metadata": {},
   "source": [
    "# Profiles\n",
    "\n",
    "Independent Variables (Predictors):\n",
    "Age \tFamily_Cnt \tNew_fare \tSex_male \tPclass_2 \tPclass_3 \tEmbarked_Q \tEmbarked_S \tCabin_ind_1\n",
    "\n",
    "Profile 1: Jack, a “20 year old” “third class” “male” passenger, won a hand of poker and his ticket to the land of the free.\n",
    "jack_data = [20,0,0,1,0,1,0,1,0]\n",
    "\n",
    "Profile 2: my_data = [36,2,0,1,1,0,0,1,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0b2da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a single row of input data\n",
    "jack_data = [20,0,0,1,0,1,0,1,0]\n",
    "# predict the class label\n",
    "jack = lr_model.predict([jack_data])\n",
    "# summarize the predicted class\n",
    "print('Jack - Survived: %d' % jack[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc99a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = [36,2,0,1,1,0,0,1,0]\n",
    "me = lr_model.predict([my_data])\n",
    "\n",
    "print('Saikat - Survived: %d' % me[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7aa04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_data = [36,2,0,0,1,0,0,1,0]\n",
    "not_me = lr_model.predict([modified_data])\n",
    "\n",
    "print('After tweaking data - Survived: %d' % not_me[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d001af",
   "metadata": {},
   "source": [
    "# Further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc05ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(Y_test_data, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcea211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Confusion Matrix and slice it into four pieces\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test_data, predictions)\n",
    "print('Confusion matrix\\n\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556ee8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize confusion matrix with seaborn heatmap\n",
    "\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Predicted -ve:0', 'Predicted +ve:1'], \n",
    "                                 index=['Actual -ve:0', 'Actual +ve:1'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb22bada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy = (TP+TN)/(Total) (manually calculated is same as obtained from lr_model.score)\n",
    "\n",
    "(90+54)/(90+15+20+54)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055707a2",
   "metadata": {},
   "source": [
    "# Precision & Recall: When One Class is More Important\n",
    "\n",
    "In many cases, it is more important to identify members of one class, e.g.,\n",
    "Tax fraud\n",
    "Credit default\n",
    "Response to a promotional offer\n",
    "Predicting delayed flights\n",
    "However data has class imbalance.\n",
    "\n",
    "In such cases, we will either increase or decrease the cut-off to better identify the important class for further attention\n",
    "\n",
    "We may be willing to tolerate greater overall error in return for better identifying the important class.\n",
    "\n",
    "Recall – we don’t want to miss anyone (false classifying is fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334e494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision = TP/(TP+FP)\n",
    "# True positive/ Predicted positive\n",
    "\n",
    "print(54/(54+15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c655e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall = TP/(TP+FN)\n",
    "# True positive/ Actual positive\n",
    "\n",
    "print(54/(54+20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f86007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dmba # to install a package in jupyter otherwise can install in Anaconda shell\n",
    "\n",
    "from dmba import classificationSummary\n",
    "classificationSummary(Y_test_data, predictions, class_names = ['not-survived','survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8b1417",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_prob = lr_model.predict_proba(X_test_data)\n",
    "prediction_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8c6173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try different threshold and check precision and recall\n",
    "\n",
    "prediction_prob = lr_model.predict_proba(X_test_data)[:,1] # take the second column which is the probability for survived (i.e., 1, column 0 is the probability for not survived (i.e., 0)\n",
    "\n",
    "\n",
    "#predictions_threshold = 0.8 precision increase (since as threshold increases prediction of survived in denominator is less), however recall decrease\n",
    "\n",
    "prediction_prob[prediction_prob > 0.8] = 1 \n",
    "prediction_prob[prediction_prob <= 0.8] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e7d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificationSummary(Y_test_data, prediction_prob, class_names = ['not-survived','survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f9b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision = TP/(TP+FP)\n",
    "# True positive/ Predicted positive\n",
    "\n",
    "print(32/(32+3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cfdea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall = TP/(TP+FN)\n",
    "# True positive/ Actual positive\n",
    "\n",
    "print(32/(32+42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbae2f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "# Generate precision recall curve values: precision, recall, thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(Y_test_data, prediction_prob)\n",
    "\n",
    "# Plot Precision Recall curve\n",
    "plt.plot(precision, recall)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e85ce3d",
   "metadata": {},
   "source": [
    "# ROC Curve\n",
    "\n",
    "Plotting FPR (false-positive rate) (x-axis as 1- specificity) and TPR (true positive rate) (y-axis as sensitivity)\n",
    "\n",
    "Whether algorithm has differentiating ability – if don’t have then 45-degree line, area under the curve is an accuracy measure, more than 0.5 for good model\n",
    "\n",
    "If increased threshold value to 0.8, whether precision, recall will increase?\n",
    "When threshold increases, the probability of detecting positive is becoming stricter, then predicted positives will become less the denominator of precision goes down, precision will go up and recall will come down\n",
    "\n",
    "If decreased threshold value to 0.2, whether precision, recall will increase? \n",
    "The reverse happens predicted survived increase so denominator of precision becomes more precision will fall and recall will rise\n",
    "Will increase recall since most people in 1 will be predicted but at same time more people who had died will be predicted as survived.\n",
    "\n",
    "AUC = 0.79 means fairly differentiable model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1411d7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test_data, predictions)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "print(\"AUC - \",format(roc_auc))\n",
    "# Plot Precision Recall curve\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35efa896",
   "metadata": {},
   "source": [
    "# F-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630b00f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(Y_test_data, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee5df5c",
   "metadata": {},
   "source": [
    "# Explore: Alternative library for  Classification using Logistic Regression - Stats Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4509c13",
   "metadata": {},
   "source": [
    "# Explore: Alternative Algorithm for Classification using Decision Tree - DecisionTreeClassifier from sklearn.tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
